{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, \"/home/mafzhang/code/CHLA-Imputation-and-Prediction-for-Bay/\")\n",
    "print(sys.path)\n",
    "from dataset.dataset_imputation import PRE8dDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser(description='Imputation')\n",
    "\n",
    "# args for area and methods\n",
    "parser.add_argument('--area', type=str, default='PRE', help='which bay area we focus')\n",
    "\n",
    "# basic args\n",
    "parser.add_argument('--epochs', type=int, default=500, help='epochs')\n",
    "parser.add_argument('--batch_size', type=int, default=16, help='batch size')\n",
    "parser.add_argument('--lr', type=float, default=1e-3, help='learning rate')\n",
    "parser.add_argument('--wd', type=float, default=1e-4, help='weight decay')\n",
    "parser.add_argument('--test_freq', type=int, default=500, help='test per n epochs')\n",
    "parser.add_argument('--embedding_size', type=int, default=32)\n",
    "parser.add_argument('--hidden_channels', type=int, default=32)\n",
    "parser.add_argument('--diffusion_embedding_size', type=int, default=64)\n",
    "parser.add_argument('--side_channels', type=int, default=1)\n",
    "\n",
    "# args for tasks\n",
    "parser.add_argument('--in_len', type=int, default=46)\n",
    "parser.add_argument('--out_len', type=int, default=46)\n",
    "parser.add_argument('--missing_ratio', type=float, default=0.1)\n",
    "\n",
    "# args for diffusion\n",
    "parser.add_argument('--beta_start', type=float, default=0.0001, help='beta start from this')\n",
    "parser.add_argument('--beta_end', type=float, default=0.2, help='beta end to this')\n",
    "parser.add_argument('--num_steps', type=float, default=50, help='denoising steps')\n",
    "parser.add_argument('--num_samples', type=int, default=10, help='n datasets')\n",
    "parser.add_argument('--schedule', type=str, default='quad', help='noise schedule type')\n",
    "parser.add_argument('--target_strategy', type=str, default='random', help='mask')\n",
    "\n",
    "# args for mae\n",
    "parser.add_argument('--num_heads', type=int, default=8, help='n heads for self attention')\n",
    "config = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "test_dloader = DataLoader(PRE8dDataset(config, mode='test'), 1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas, data_ob_masks, data_gt_masks, labels, label_masks = next(iter(test_dloader))\n",
    "device = \"cuda\"\n",
    "datas, data_ob_masks, data_gt_masks, labels, label_masks = datas.float().to(device), data_ob_masks.to(device), data_gt_masks.to(device), labels.to(device), label_masks.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"../../log/imputation/PRE/GraphDiffusion/best_0.1.pt\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_mask = data_gt_masks\n",
    "adj = np.load(\"/home/mafzhang/data/{}/8d/adj.npy\".format(config.area))\n",
    "adj = torch.from_numpy(adj).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_data_our = model.impute(datas, cond_mask, adj, 10)\n",
    "imputed_data_our = imputed_data_our.median(1).values\n",
    "mask = data_ob_masks - cond_mask\n",
    "imputed_our = imputed_data_our[0][mask.bool().cpu()[0]]\n",
    "truth = datas[0][mask.bool()[0]].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "from model.dineof import DINEOF\n",
    "model = DINEOF(10, [60, 96, config.in_len])\n",
    "is_sea = np.load(\"/home/mafzhang/data/PRE/8d/is_sea.npy\")\n",
    "datas_image = torch.zeros(1,46,1,60,96)\n",
    "datas_image = datas_image.to(device)\n",
    "datas_image[:,:,:,is_sea.astype(bool)]=datas\n",
    "cond_mask_image = torch.zeros(1,46,1,60,96)\n",
    "cond_mask_image = cond_mask_image.to(device)\n",
    "cond_mask_image[:,:,:,is_sea.astype(bool)]=cond_mask\n",
    "ob_mask_image = torch.zeros(1,46,1,60,96)\n",
    "ob_mask_image = ob_mask_image.to(device)\n",
    "ob_mask_image[:,:,:,is_sea.astype(bool)]=data_ob_masks\n",
    "\n",
    "tmp_data = torch.where(cond_mask_image.cpu()==0, float(\"nan\"), datas_image.cpu())\n",
    "tmp_data = rearrange(tmp_data, \"b t c h w -> (b h w c t)\")\n",
    "tmp_data = tmp_data.cpu().numpy()\n",
    "time = torch.arange(datas_image.shape[1]).unsqueeze(0).unsqueeze(0).expand(datas_image.shape[-2], datas_image.shape[-1], -1).reshape(-1)\n",
    "lati = torch.arange(datas_image.shape[-2]).unsqueeze(-1).unsqueeze(-1).expand(-1, datas_image.shape[-1], datas_image.shape[1]).reshape(-1)\n",
    "lon = torch.arange(datas_image.shape[-1]).unsqueeze(0).unsqueeze(-1).expand(datas_image.shape[-2], -1, datas_image.shape[1]).reshape(-1)\n",
    "x = np.stack([lati.numpy(), lon.numpy(), time.numpy()], axis=1)\n",
    "print(x.shape)\n",
    "print(tmp_data.shape)\n",
    "model.fit(x, tmp_data)\n",
    "\n",
    "imputed_data = model.predict(x)\n",
    "imputed_data = rearrange(imputed_data, \"(b t c h w)->b t c h w\", b=1, t=datas_image.shape[1], c=1, h=datas_image.shape[-2], w=datas_image.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_data_dineof = imputed_data[:,:,:,is_sea.astype(bool)]\n",
    "imputed_dineof = imputed_data_dineof[0][mask.bool().cpu()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_our = imputed_our[:1000]\n",
    "imputed_dineof = imputed_dineof[:1000]\n",
    "truth = truth[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stat\n",
    "import pandas as pd\n",
    "method = []\n",
    "method.extend(['STImp' for i in range(imputed_our.shape[0])])\n",
    "method.extend(['DINEOF' for i in range(imputed_our.shape[0])])\n",
    "data = {'truth': np.concatenate([truth.numpy() for i in range(2)]),\n",
    "        'imputed':np.concatenate([imputed_our.numpy(), imputed_dineof]),\n",
    "        'method':method}\n",
    "data = pd.DataFrame.from_dict(data)\n",
    "color =[\"#9F0000\",\"#576fa0\"]\n",
    "g=sns.jointplot(data=data, x=\"truth\", y=\"imputed\", hue=\"method\", palette=color, marginal_kws={'common_norm':False})\n",
    "# plt.scatter(truth, imputed_our,s=10, c=\"#9F0000\",label=\"Our\")\n",
    "# plt.scatter(truth, imputed_mae.cpu().detach().numpy(),s=10, c=\"#e3b87f\", label=\"MAE\")\n",
    "# plt.scatter(truth, imputed_itp.cpu(),s=10, c=\"#576fa0\", label=\"Lin-ITP\")\n",
    "xpoints = ypoints = plt.xlim()\n",
    "plt.plot(xpoints, ypoints, 'k-', alpha=0.75, zorder=0)\n",
    "plt.legend()\n",
    "plt.ylabel(\"imputed\", size=24)\n",
    "plt.xlabel(\"truth\", size=24)\n",
    "print(stat.pearsonr(truth[:1000], imputed_our))\n",
    "print(stat.pearsonr(truth[:1000], imputed_dineof))\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.missing_ratio=0.5\n",
    "from torch.utils.data import DataLoader\n",
    "test_dloader = DataLoader(PRE8dDataset(config, mode='test'), 1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas, data_ob_masks, data_gt_masks, labels, label_masks = next(iter(test_dloader))\n",
    "device = \"cuda\"\n",
    "datas, data_ob_masks, data_gt_masks, labels, label_masks = datas.float().to(device), data_ob_masks.to(device), data_gt_masks.to(device), labels.to(device), label_masks.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"../../log/imputation/PRE/GraphDiffusion/best_0.5.pt\")\n",
    "model = model.to(device)\n",
    "cond_mask = data_gt_masks\n",
    "adj = np.load(\"/home/mafzhang/data/{}/8d/adj.npy\".format(config.area))\n",
    "adj = torch.from_numpy(adj).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_data_our = model.impute(datas, cond_mask, adj, 10)\n",
    "imputed_data_our = imputed_data_our.median(1).values\n",
    "mask = data_ob_masks - cond_mask\n",
    "imputed_our = imputed_data_our[0][mask.bool().cpu()[0]]\n",
    "truth = datas[0][mask.bool()[0]].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "from model.dineof import DINEOF\n",
    "model = DINEOF(10, [60, 96, config.in_len])\n",
    "is_sea = np.load(\"/home/mafzhang/data/PRE/8d/is_sea.npy\")\n",
    "datas_image = torch.zeros(1,46,1,60,96)\n",
    "datas_image = datas_image.to(device)\n",
    "datas_image[:,:,:,is_sea.astype(bool)]=datas\n",
    "cond_mask_image = torch.zeros(1,46,1,60,96)\n",
    "cond_mask_image = cond_mask_image.to(device)\n",
    "cond_mask_image[:,:,:,is_sea.astype(bool)]=cond_mask\n",
    "ob_mask_image = torch.zeros(1,46,1,60,96)\n",
    "ob_mask_image = ob_mask_image.to(device)\n",
    "ob_mask_image[:,:,:,is_sea.astype(bool)]=data_ob_masks\n",
    "\n",
    "tmp_data = torch.where(cond_mask_image.cpu()==0, float(\"nan\"), datas_image.cpu())\n",
    "tmp_data = torch.where(ob_mask_image.cpu()==0, float(\"nan\"), tmp_data)\n",
    "tmp_data = rearrange(tmp_data, \"b t c h w -> (b h w c t)\")\n",
    "tmp_data = tmp_data.cpu().numpy()\n",
    "time = torch.arange(datas_image.shape[1]).unsqueeze(0).unsqueeze(0).expand(datas_image.shape[-2], datas_image.shape[-1], -1).reshape(-1)\n",
    "lati = torch.arange(datas_image.shape[-2]).unsqueeze(-1).unsqueeze(-1).expand(-1, datas_image.shape[-1], datas_image.shape[1]).reshape(-1)\n",
    "lon = torch.arange(datas_image.shape[-1]).unsqueeze(0).unsqueeze(-1).expand(datas_image.shape[-2], -1, datas_image.shape[1]).reshape(-1)\n",
    "x = np.stack([lati.numpy(), lon.numpy(), time.numpy()], axis=1)\n",
    "print(x.shape)\n",
    "print(tmp_data.shape)\n",
    "model.fit(x, tmp_data)\n",
    "\n",
    "imputed_data = model.predict(x)\n",
    "imputed_data = rearrange(imputed_data, \"(b t c h w)->b t c h w\", b=1, t=datas_image.shape[1], c=1, h=datas_image.shape[-2], w=datas_image.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_data_dineof = imputed_data[:,:,:,is_sea.astype(bool)]\n",
    "imputed_dineof = imputed_data_dineof[0][mask.bool().cpu()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_our = imputed_our[:1000]\n",
    "imputed_dineof = imputed_dineof[:1000]\n",
    "truth = truth[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stat\n",
    "import pandas as pd\n",
    "method = []\n",
    "method.extend(['STImp' for i in range(imputed_our.shape[0])])\n",
    "method.extend(['DINEOF' for i in range(imputed_our.shape[0])])\n",
    "data = {'truth': np.concatenate([truth.numpy() for i in range(2)]),\n",
    "        'imputed':np.concatenate([imputed_our.numpy(), imputed_dineof]),\n",
    "        'method':method}\n",
    "data = pd.DataFrame.from_dict(data)\n",
    "color =[\"#9F0000\",\"#576fa0\"]\n",
    "g=sns.jointplot(data=data, x=\"truth\", y=\"imputed\", hue=\"method\", palette=color, marginal_kws={'common_norm':False})\n",
    "# plt.scatter(truth, imputed_our,s=10, c=\"#9F0000\",label=\"Our\")\n",
    "# plt.scatter(truth, imputed_mae.cpu().detach().numpy(),s=10, c=\"#e3b87f\", label=\"MAE\")\n",
    "# plt.scatter(truth, imputed_itp.cpu(),s=10, c=\"#576fa0\", label=\"Lin-ITP\")\n",
    "xpoints = ypoints = plt.xlim()\n",
    "plt.plot(xpoints, ypoints, 'k-', alpha=0.75, zorder=0)\n",
    "plt.legend()\n",
    "plt.ylabel(\"imputed\", size=24)\n",
    "plt.xlabel(\"truth\", size=24)\n",
    "print(stat.pearsonr(truth[:1000], imputed_our))\n",
    "print(stat.pearsonr(truth[:1000], imputed_dineof))\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.missing_ratio=0.9\n",
    "from torch.utils.data import DataLoader\n",
    "test_dloader = DataLoader(PRE8dDataset(config, mode='test'), 1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas, data_ob_masks, data_gt_masks, labels, label_masks = next(iter(test_dloader))\n",
    "device = \"cuda\"\n",
    "datas, data_ob_masks, data_gt_masks, labels, label_masks = datas.float().to(device), data_ob_masks.to(device), data_gt_masks.to(device), labels.to(device), label_masks.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"../../log/imputation/PRE/GraphDiffusion/best_0.9.pt\")\n",
    "model = model.to(device)\n",
    "cond_mask = data_gt_masks\n",
    "adj = np.load(\"/home/mafzhang/data/{}/8d/adj.npy\".format(config.area))\n",
    "adj = torch.from_numpy(adj).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_data_our = model.impute(datas, cond_mask, adj, 10)\n",
    "imputed_data_our = imputed_data_our.median(1).values\n",
    "mask = data_ob_masks - cond_mask\n",
    "imputed_our = imputed_data_our[0][mask.bool().cpu()[0]]\n",
    "truth = datas[0][mask.bool()[0]].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "from model.dineof import DINEOF\n",
    "model = DINEOF(10, [60, 96, config.in_len])\n",
    "is_sea = np.load(\"/home/mafzhang/data/PRE/8d/is_sea.npy\")\n",
    "datas_image = torch.zeros(1,46,1,60,96)\n",
    "datas_image = datas_image.to(device)\n",
    "datas_image[:,:,:,is_sea.astype(bool)]=datas\n",
    "cond_mask_image = torch.zeros(1,46,1,60,96)\n",
    "cond_mask_image = cond_mask_image.to(device)\n",
    "cond_mask_image[:,:,:,is_sea.astype(bool)]=cond_mask\n",
    "ob_mask_image = torch.zeros(1,46,1,60,96)\n",
    "ob_mask_image = ob_mask_image.to(device)\n",
    "ob_mask_image[:,:,:,is_sea.astype(bool)]=data_ob_masks\n",
    "\n",
    "tmp_data = torch.where(cond_mask_image.cpu()==0, float(\"nan\"), datas_image.cpu())\n",
    "tmp_data = torch.where(ob_mask_image.cpu()==0, float(\"nan\"), tmp_data)\n",
    "tmp_data = rearrange(tmp_data, \"b t c h w -> (b h w c t)\")\n",
    "tmp_data = tmp_data.cpu().numpy()\n",
    "time = torch.arange(datas_image.shape[1]).unsqueeze(0).unsqueeze(0).expand(datas_image.shape[-2], datas_image.shape[-1], -1).reshape(-1)\n",
    "lati = torch.arange(datas_image.shape[-2]).unsqueeze(-1).unsqueeze(-1).expand(-1, datas_image.shape[-1], datas_image.shape[1]).reshape(-1)\n",
    "lon = torch.arange(datas_image.shape[-1]).unsqueeze(0).unsqueeze(-1).expand(datas_image.shape[-2], -1, datas_image.shape[1]).reshape(-1)\n",
    "x = np.stack([lati.numpy(), lon.numpy(), time.numpy()], axis=1)\n",
    "print(x.shape)\n",
    "print(tmp_data.shape)\n",
    "model.fit(x, tmp_data)\n",
    "\n",
    "imputed_data = model.predict(x)\n",
    "imputed_data = rearrange(imputed_data, \"(b t c h w)->b t c h w\", b=1, t=datas_image.shape[1], c=1, h=datas_image.shape[-2], w=datas_image.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_data_dineof = imputed_data[:,:,:,is_sea.astype(bool)]\n",
    "imputed_dineof = imputed_data_dineof[0][mask.bool().cpu()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_our = imputed_our[:1000]\n",
    "imputed_dineof = imputed_dineof[:1000]\n",
    "truth = truth[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stat\n",
    "import pandas as pd\n",
    "method = []\n",
    "method.extend(['STImp' for i in range(imputed_our.shape[0])])\n",
    "method.extend(['DINEOF' for i in range(imputed_our.shape[0])])\n",
    "data = {'truth': np.concatenate([truth.numpy() for i in range(2)]),\n",
    "        'imputed':np.concatenate([imputed_our.numpy(), imputed_dineof]),\n",
    "        'method':method}\n",
    "data = pd.DataFrame.from_dict(data)\n",
    "color =[\"#9F0000\",\"#576fa0\"]\n",
    "g=sns.jointplot(data=data, x=\"truth\", y=\"imputed\", hue=\"method\", palette=color, marginal_kws={'common_norm':False})\n",
    "# plt.scatter(truth, imputed_our,s=10, c=\"#9F0000\",label=\"Our\")\n",
    "# plt.scatter(truth, imputed_mae.cpu().detach().numpy(),s=10, c=\"#e3b87f\", label=\"MAE\")\n",
    "# plt.scatter(truth, imputed_itp.cpu(),s=10, c=\"#576fa0\", label=\"Lin-ITP\")\n",
    "xpoints = ypoints = plt.xlim()\n",
    "plt.plot(xpoints, ypoints, 'k-', alpha=0.75, zorder=0)\n",
    "plt.legend()\n",
    "plt.ylabel(\"imputed\", size=24)\n",
    "plt.xlabel(\"truth\", size=24)\n",
    "print(stat.pearsonr(truth[:1000], imputed_our))\n",
    "print(stat.pearsonr(truth[:1000], imputed_dineof))\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "test_dloader = DataLoader(PRE8dDataset(config, mode='test'), 1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas, data_ob_masks, data_gt_masks, labels, label_masks = next(iter(test_dloader))\n",
    "device = \"cuda\"\n",
    "datas, data_ob_masks, data_gt_masks, labels, label_masks = datas.float().to(device), data_ob_masks.to(device), data_gt_masks.to(device), labels.to(device), label_masks.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"../../log/imputation/PRE/GraphDiffusion/best_0.1.pt\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_mask = data_gt_masks\n",
    "adj = np.load(\"/home/mafzhang/data/{}/8d/adj.npy\".format(config.area))\n",
    "adj = torch.from_numpy(adj).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_data_our = model.impute(datas, cond_mask, adj, 10)\n",
    "imputed_data_our = imputed_data_our.median(1).values\n",
    "truth = datas[0]\n",
    "truth[~data_ob_masks[0].bool()]=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "from model.dineof import DINEOF\n",
    "model = DINEOF(10, [60, 96, config.in_len])\n",
    "is_sea = np.load(\"/home/mafzhang/data/PRE/8d/is_sea.npy\")\n",
    "datas_image = torch.zeros(1,46,1,60,96)\n",
    "datas_image = datas_image.to(device)\n",
    "datas_image[:,:,:,is_sea.astype(bool)]=datas\n",
    "cond_mask_image = torch.zeros(1,46,1,60,96)\n",
    "cond_mask_image = cond_mask_image.to(device)\n",
    "cond_mask_image[:,:,:,is_sea.astype(bool)]=cond_mask\n",
    "ob_mask_image = torch.zeros(1,46,1,60,96)\n",
    "ob_mask_image = ob_mask_image.to(device)\n",
    "ob_mask_image[:,:,:,is_sea.astype(bool)]=data_ob_masks\n",
    "\n",
    "tmp_data = torch.where(cond_mask_image.cpu()==0, float(\"nan\"), datas_image.cpu())\n",
    "tmp_data = torch.where(ob_mask_image.cpu()==0, float(\"nan\"), tmp_data)\n",
    "tmp_data = rearrange(tmp_data, \"b t c h w -> (b h w c t)\")\n",
    "tmp_data = tmp_data.cpu().numpy()\n",
    "time = torch.arange(datas_image.shape[1]).unsqueeze(0).unsqueeze(0).expand(datas_image.shape[-2], datas_image.shape[-1], -1).reshape(-1)\n",
    "lati = torch.arange(datas_image.shape[-2]).unsqueeze(-1).unsqueeze(-1).expand(-1, datas_image.shape[-1], datas_image.shape[1]).reshape(-1)\n",
    "lon = torch.arange(datas_image.shape[-1]).unsqueeze(0).unsqueeze(-1).expand(datas_image.shape[-2], -1, datas_image.shape[1]).reshape(-1)\n",
    "x = np.stack([lati.numpy(), lon.numpy(), time.numpy()], axis=1)\n",
    "print(x.shape)\n",
    "print(tmp_data.shape)\n",
    "model.fit(x, tmp_data)\n",
    "\n",
    "imputed_data = model.predict(x)\n",
    "imputed_data = rearrange(imputed_data, \"(b t c h w)->b t c h w\", b=1, t=datas_image.shape[1], c=1, h=datas_image.shape[-2], w=datas_image.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_dineof = imputed_data[0,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_stimp = torch.zeros(46,60,96)\n",
    "imputed_stimp[:,is_sea.astype(bool)]=imputed_data_our[0,:,0]\n",
    "observed = torch.zeros(46,60,96)\n",
    "observed[:,is_sea.astype(bool)]=truth.cpu().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import basemap\n",
    "from sklearn.cluster import KMeans, DBSCAN, SpectralClustering\n",
    "import cartopy.crs as ccrs\n",
    "from copy import deepcopy\n",
    "import h5py\n",
    "from numpy import meshgrid\n",
    "import numpy as np\n",
    "\n",
    "t=0\n",
    "is_sea2=np.load(\"/home/mafzhang/data/PRE/8d/is_sea_2.npy\")\n",
    "tmp = deepcopy(observed[t].numpy())\n",
    "tmp[~is_sea2.astype(bool)]= np.nan\n",
    "raw_data = h5py.File(\"/home/mafzhang/data/PRE/8d/modis_chla_8d_4km_pre.mat\", 'r')\n",
    "lon = np.array(raw_data['longitude']).squeeze()\n",
    "lati = np.array(raw_data['latitude']).squeeze()\n",
    "\n",
    "[x,y] = meshgrid(lon, lati)\n",
    "\n",
    "\n",
    "lon1, lon2, lati1, lati2 = lon.min(), lon.max(), lati.min(), lati.max()\n",
    "map = basemap.Basemap(llcrnrlon=lon1, llcrnrlat=lati1,urcrnrlon=lon2, urcrnrlat=lati2, projection='cyl', resolution='f')\n",
    "# map.fillcontinents(color='white')\n",
    "map.drawlsmask(land_color='white', ocean_color='lightgray', resolution='f',grid=1.25)\n",
    "# map.bluemarble()\n",
    "map.drawcoastlines()\n",
    "map.contourf(x, y, tmp, levels=np.linspace(-1.5, 1.5, 40),cmap=\"rainbow\",extend='both')\n",
    "\n",
    "# map.contourf(x, y, tmp2, levels=np.linspace(-1.5, 1.5, 40),cmap=\"Greys\")\n",
    "# map.colorbar(boundaries=np.linspace(-1.5, 1.5, 20), ticks=np.linspace(-1.5, 1.5, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import basemap\n",
    "from sklearn.cluster import KMeans, DBSCAN, SpectralClustering\n",
    "import cartopy.crs as ccrs\n",
    "from copy import deepcopy\n",
    "import h5py\n",
    "from numpy import meshgrid\n",
    "import numpy as np\n",
    "\n",
    "t=0\n",
    "tmp = deepcopy(imputed_dineof[t])\n",
    "mask = np.zeros_like(tmp)\n",
    "mask[is_sea.astype(bool)]=data_ob_masks[0,t,0].cpu()\n",
    "tmp = np.where(mask, observed[t].numpy(), tmp)\n",
    "tmp[~is_sea2.astype(bool)]= np.nan\n",
    "\n",
    "lon1, lon2, lati1, lati2 = lon.min(), lon.max(), lati.min(), lati.max()\n",
    "map = basemap.Basemap(llcrnrlon=lon1, llcrnrlat=lati1,urcrnrlon=lon2, urcrnrlat=lati2, projection='cyl', resolution='f')\n",
    "map.drawlsmask(land_color='white', ocean_color='lightgray', resolution='f',grid=1.25)\n",
    "# map.bluemarble()\n",
    "map.drawcoastlines()\n",
    "map.contourf(x, y, tmp, levels=np.linspace(-1.5, 1.5, 40),cmap=\"rainbow\",extend='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import basemap\n",
    "from sklearn.cluster import KMeans, DBSCAN, SpectralClustering\n",
    "import cartopy.crs as ccrs\n",
    "from copy import deepcopy\n",
    "import h5py\n",
    "from numpy import meshgrid\n",
    "import numpy as np\n",
    "\n",
    "t=0\n",
    "tmp = deepcopy(imputed_stimp[t].numpy())\n",
    "tmp[~is_sea2.astype(bool)]= np.nan\n",
    "\n",
    "[x,y] = meshgrid(lon, lati)\n",
    "\n",
    "\n",
    "lon1, lon2, lati1, lati2 = lon.min(), lon.max(), lati.min(), lati.max()\n",
    "map = basemap.Basemap(llcrnrlon=lon1, llcrnrlat=lati1,urcrnrlon=lon2, urcrnrlat=lati2, projection='cyl', resolution='f')\n",
    "# map.fillcontinents(color='white')\n",
    "map.drawlsmask(land_color='white', ocean_color='lightgray', resolution='f',grid=1.25)\n",
    "# map.bluemarble()\n",
    "map.drawcoastlines()\n",
    "map.contourf(x, y, tmp, levels=np.linspace(-1.5, 1.5, 40),cmap=\"rainbow\",extend='both')\n",
    "\n",
    "# map.contourf(x, y, tmp2, levels=np.linspace(-1.5, 1.5, 40),cmap=\"Greys\")\n",
    "map.colorbar(boundaries=np.linspace(-1.5, 1.5, 20), ticks=np.linspace(-1.5, 1.5, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import basemap\n",
    "from sklearn.cluster import KMeans, DBSCAN, SpectralClustering\n",
    "import cartopy.crs as ccrs\n",
    "from copy import deepcopy\n",
    "import h5py\n",
    "from numpy import meshgrid\n",
    "import numpy as np\n",
    "\n",
    "t=13\n",
    "tmp = deepcopy(observed[t].numpy())\n",
    "tmp[~is_sea2.astype(bool)]= np.nan\n",
    "raw_data = h5py.File(\"/home/mafzhang/data/PRE/8d/modis_chla_8d_4km_pre.mat\", 'r')\n",
    "lon = np.array(raw_data['longitude']).squeeze()\n",
    "lati = np.array(raw_data['latitude']).squeeze()\n",
    "\n",
    "[x,y] = meshgrid(lon, lati)\n",
    "\n",
    "\n",
    "lon1, lon2, lati1, lati2 = lon.min(), lon.max(), lati.min(), lati.max()\n",
    "map = basemap.Basemap(llcrnrlon=lon1, llcrnrlat=lati1,urcrnrlon=lon2, urcrnrlat=lati2, projection='cyl', resolution='f')\n",
    "# map.fillcontinents(color='white')\n",
    "map.drawlsmask(land_color='white', ocean_color='lightgray', resolution='f',grid=1.25)\n",
    "# map.bluemarble()\n",
    "map.drawcoastlines()\n",
    "map.contourf(x, y, tmp, levels=np.linspace(-1.5, 1.5, 40),cmap=\"rainbow\",extend='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import basemap\n",
    "from sklearn.cluster import KMeans, DBSCAN, SpectralClustering\n",
    "import cartopy.crs as ccrs\n",
    "from copy import deepcopy\n",
    "import h5py\n",
    "from numpy import meshgrid\n",
    "import numpy as np\n",
    "\n",
    "tmp = deepcopy(imputed_dineof[t])\n",
    "mask = np.zeros_like(tmp)\n",
    "mask[is_sea.astype(bool)]=data_ob_masks[0,t,0].cpu()\n",
    "tmp = np.where(mask, observed[t].numpy(), tmp)\n",
    "tmp[~is_sea2.astype(bool)]= np.nan\n",
    "\n",
    "lon1, lon2, lati1, lati2 = lon.min(), lon.max(), lati.min(), lati.max()\n",
    "map = basemap.Basemap(llcrnrlon=lon1, llcrnrlat=lati1,urcrnrlon=lon2, urcrnrlat=lati2, projection='cyl', resolution='f')\n",
    "map.drawlsmask(land_color='white', ocean_color='lightgray', resolution='f',grid=1.25)\n",
    "# map.bluemarble()\n",
    "map.drawcoastlines()\n",
    "map.contourf(x, y, tmp, levels=np.linspace(-1.5, 1.5, 40),cmap=\"rainbow\",extend='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import basemap\n",
    "from sklearn.cluster import KMeans, DBSCAN, SpectralClustering\n",
    "import cartopy.crs as ccrs\n",
    "from copy import deepcopy\n",
    "import h5py\n",
    "from numpy import meshgrid\n",
    "import numpy as np\n",
    "\n",
    "tmp = deepcopy(imputed_stimp[t].numpy())\n",
    "tmp[~is_sea2.astype(bool)]= np.nan\n",
    "\n",
    "[x,y] = meshgrid(lon, lati)\n",
    "\n",
    "\n",
    "lon1, lon2, lati1, lati2 = lon.min(), lon.max(), lati.min(), lati.max()\n",
    "map = basemap.Basemap(llcrnrlon=lon1, llcrnrlat=lati1,urcrnrlon=lon2, urcrnrlat=lati2, projection='cyl', resolution='f')\n",
    "# map.fillcontinents(color='white')\n",
    "map.drawlsmask(land_color='white', ocean_color='lightgray', resolution='f',grid=1.25)\n",
    "# map.bluemarble()\n",
    "map.drawcoastlines()\n",
    "map.contourf(x, y, tmp, levels=np.linspace(-1.5, 1.5, 40),cmap=\"rainbow\",extend='both')\n",
    "\n",
    "# map.contourf(x, y, tmp2, levels=np.linspace(-1.5, 1.5, 40),cmap=\"Greys\")\n",
    "map.colorbar(boundaries=np.linspace(-1.5, 1.5, 20), ticks=np.linspace(-1.5, 1.5, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import basemap\n",
    "from sklearn.cluster import KMeans, DBSCAN, SpectralClustering\n",
    "import cartopy.crs as ccrs\n",
    "from copy import deepcopy\n",
    "import h5py\n",
    "from numpy import meshgrid\n",
    "import numpy as np\n",
    "\n",
    "t=37\n",
    "tmp = deepcopy(observed[t].numpy())\n",
    "tmp[~is_sea2.astype(bool)]= np.nan\n",
    "raw_data = h5py.File(\"/home/mafzhang/data/PRE/8d/modis_chla_8d_4km_pre.mat\", 'r')\n",
    "lon = np.array(raw_data['longitude']).squeeze()\n",
    "lati = np.array(raw_data['latitude']).squeeze()\n",
    "\n",
    "[x,y] = meshgrid(lon, lati)\n",
    "\n",
    "\n",
    "lon1, lon2, lati1, lati2 = lon.min(), lon.max(), lati.min(), lati.max()\n",
    "map = basemap.Basemap(llcrnrlon=lon1, llcrnrlat=lati1,urcrnrlon=lon2, urcrnrlat=lati2, projection='cyl', resolution='f')\n",
    "# map.fillcontinents(color='white')\n",
    "map.drawlsmask(land_color='white', ocean_color='lightgray', resolution='f',grid=1.25)\n",
    "# map.bluemarble()\n",
    "map.drawcoastlines()\n",
    "map.contourf(x, y, tmp, levels=np.linspace(-1.5, 1.5, 40),cmap=\"rainbow\",extend='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import basemap\n",
    "from sklearn.cluster import KMeans, DBSCAN, SpectralClustering\n",
    "import cartopy.crs as ccrs\n",
    "from copy import deepcopy\n",
    "import h5py\n",
    "from numpy import meshgrid\n",
    "import numpy as np\n",
    "\n",
    "tmp = deepcopy(imputed_dineof[t])\n",
    "mask = np.zeros_like(tmp)\n",
    "mask[is_sea.astype(bool)]=data_ob_masks[0,t,0].cpu()\n",
    "tmp = np.where(mask, observed[t].numpy(), tmp)\n",
    "tmp[~is_sea2.astype(bool)]= np.nan\n",
    "\n",
    "lon1, lon2, lati1, lati2 = lon.min(), lon.max(), lati.min(), lati.max()\n",
    "map = basemap.Basemap(llcrnrlon=lon1, llcrnrlat=lati1,urcrnrlon=lon2, urcrnrlat=lati2, projection='cyl', resolution='f')\n",
    "map.drawlsmask(land_color='white', ocean_color='lightgray', resolution='f',grid=1.25)\n",
    "# map.bluemarble()\n",
    "map.drawcoastlines()\n",
    "map.contourf(x, y, tmp, levels=np.linspace(-1.5, 1.5, 40),cmap=\"rainbow\",extend='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import basemap\n",
    "from sklearn.cluster import KMeans, DBSCAN, SpectralClustering\n",
    "import cartopy.crs as ccrs\n",
    "from copy import deepcopy\n",
    "import h5py\n",
    "from numpy import meshgrid\n",
    "import numpy as np\n",
    "\n",
    "tmp = deepcopy(imputed_stimp[t].numpy())\n",
    "tmp[~is_sea2.astype(bool)]= np.nan\n",
    "\n",
    "[x,y] = meshgrid(lon, lati)\n",
    "\n",
    "\n",
    "lon1, lon2, lati1, lati2 = lon.min(), lon.max(), lati.min(), lati.max()\n",
    "map = basemap.Basemap(llcrnrlon=lon1, llcrnrlat=lati1,urcrnrlon=lon2, urcrnrlat=lati2, projection='cyl', resolution='f')\n",
    "# map.fillcontinents(color='white')\n",
    "map.drawlsmask(land_color='white', ocean_color='lightgray', resolution='f',grid=1.25)\n",
    "# map.bluemarble()\n",
    "map.drawcoastlines()\n",
    "map.contourf(x, y, tmp, levels=np.linspace(-1.5, 1.5, 40),cmap=\"rainbow\",extend='both')\n",
    "\n",
    "# map.contourf(x, y, tmp2, levels=np.linspace(-1.5, 1.5, 40),cmap=\"Greys\")\n",
    "map.colorbar(boundaries=np.linspace(-1.5, 1.5, 20), ticks=np.linspace(-1.5, 1.5, 6))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch211",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
